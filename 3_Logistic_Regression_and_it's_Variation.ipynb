{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Logistic Regression**\n",
        "\n",
        "---\n",
        "\n",
        "## **1. Introduction**\n",
        "\n",
        "* **Definition:**\n",
        "  Logistic Regression is a **supervised learning algorithm** used to predict **categorical outcomes** (binary or multi-class) based on one or more independent variables.\n",
        "\n",
        "* Despite the name, it’s a **classification** algorithm, not regression.\n",
        "\n",
        "* **Example:**\n",
        "\n",
        "  * Predict whether an email is **spam (1)** or **not spam (0)**.\n",
        "  * Predict whether a patient has **diabetes (1)** or **no diabetes (0)**.\n",
        "\n",
        "---\n",
        "\n",
        "## **2. Working Principle**\n",
        "\n",
        "* Idea: Instead of predicting a continuous value (like linear regression), we **predict the probability** of a class.\n",
        "* Uses **Sigmoid function** to map any real number to a value between 0 and 1.\n",
        "\n",
        "$$\n",
        "P(Y=1|X) = \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "$$\n",
        "\n",
        "Where:\n",
        "\n",
        "* $z = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_n X_n$\n",
        "\n",
        "* $\\sigma(z)$ = sigmoid function → outputs probability between 0 and 1\n",
        "\n",
        "* Decision rule (for binary classification):\n",
        "\n",
        "$$\n",
        "\\hat{Y} =\n",
        "\\begin{cases}\n",
        "1 & \\text{if } P(Y=1|X) \\ge 0.5 \\\\\n",
        "0 & \\text{if } P(Y=1|X) < 0.5\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## **3. Mathematical Intuition**\n",
        "\n",
        "* **Linear combination:** $z = \\beta_0 + \\beta_1 X_1 + ... + \\beta_n X_n$\n",
        "* **Sigmoid transformation:** Converts linear output to probability.\n",
        "* **Cost Function:** Uses **Log Loss / Cross-Entropy** instead of MSE:\n",
        "\n",
        "$$\n",
        "J(\\beta) = - \\frac{1}{m} \\sum_{i=1}^m \\left[ y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i) \\right]\n",
        "$$\n",
        "\n",
        "Where:\n",
        "\n",
        "* $y_i$ = actual label (0 or 1)\n",
        "\n",
        "* $\\hat{y}_i$ = predicted probability\n",
        "\n",
        "* $m$ = number of samples\n",
        "\n",
        "* **Optimization:** Use **Gradient Descent** or advanced optimizers (Newton-Raphson, BFGS) to minimize log loss.\n",
        "\n",
        "---\n",
        "\n",
        "## **4. Assumptions of Logistic Regression**\n",
        "\n",
        "1. **Linearity of log-odds:** The logit (log-odds) of the outcome is linearly related to predictors.\n",
        "2. **Independent observations**\n",
        "3. **No multicollinearity** among predictors\n",
        "4. **Large sample size** → ensures stable estimates\n",
        "5. **Binary or categorical outcome** (for basic logistic regression)\n",
        "\n",
        "---\n",
        "\n",
        "## **5. Pros & Cons**\n",
        "\n",
        "### ✅ Pros\n",
        "\n",
        "* Simple and interpretable\n",
        "* Outputs probabilities → useful for risk prediction\n",
        "* Works well with **linearly separable data**\n",
        "* Can handle multiple predictors\n",
        "\n",
        "### ❌ Cons\n",
        "\n",
        "* Assumes **linear relationship between features and log-odds**\n",
        "* Sensitive to outliers\n",
        "* Cannot handle **complex non-linear decision boundaries** without feature engineering\n",
        "* Requires large datasets for stable estimates\n",
        "\n",
        "---\n",
        "\n",
        "## **6. Variants**\n",
        "\n",
        "1. **Binary Logistic Regression** → 2 classes (0/1)\n",
        "2. **Multinomial Logistic Regression** → more than 2 classes (softmax function)\n",
        "3. **Ordinal Logistic Regression** → ordered categories (e.g., low/medium/high)\n",
        "\n",
        "---\n",
        "\n",
        "## **7. Real-Life Applications**\n",
        "\n",
        "* **Healthcare:** Predict disease presence (diabetes, cancer).\n",
        "* **Finance:** Predict loan default (yes/no).\n",
        "* **Marketing:** Predict if a customer will buy a product.\n",
        "* **Email filtering:** Spam detection.\n",
        "* **Customer churn prediction:** Will a customer leave a service?\n",
        "\n",
        "---\n",
        "\n",
        "## **8. Flowchart – Logistic Regression Workflow**\n",
        "\n",
        "```\n",
        "         Input Data (X, Y)\n",
        "                 ↓\n",
        "       Data Preprocessing (scaling, encoding)\n",
        "                 ↓\n",
        "    Compute linear combination: z = β0 + β1 X1 + ... + βn Xn\n",
        "                 ↓\n",
        "       Apply Sigmoid function: σ(z) → P(Y=1|X)\n",
        "                 ↓\n",
        "        Predict class based on threshold (0.5)\n",
        "                 ↓\n",
        "         Evaluate Model (Accuracy, F1, ROC-AUC)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## **9. Key Takeaways**\n",
        "\n",
        "* Logistic Regression = classification algorithm, not regression.\n",
        "* Uses **sigmoid function** to map predictions to probabilities.\n",
        "* Cost function = **Log Loss**, optimized via Gradient Descent.\n",
        "* Simple, interpretable, widely used for **binary outcomes**.\n",
        "\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "# **Variants of Logistic Regression**\n",
        "\n",
        "---\n",
        "\n",
        "## **1. Binary Logistic Regression**\n",
        "\n",
        "### **Definition**\n",
        "\n",
        "* Used when the **dependent variable has only 2 classes** (Yes/No, 0/1, True/False).\n",
        "* Most common logistic regression type.\n",
        "\n",
        "### **Equation**\n",
        "\n",
        "$$\n",
        "P(Y=1|X) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1X_1 + \\dots + \\beta_nX_n)}}\n",
        "$$\n",
        "\n",
        "Decision rule:\n",
        "\n",
        "$$\n",
        "\\hat{Y} =\n",
        "\\begin{cases}\n",
        "1 & \\text{if } P \\geq 0.5 \\\\\n",
        "0 & \\text{if } P < 0.5\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "### **Example Applications**\n",
        "\n",
        "* Predict whether a student **passes/fails** an exam.\n",
        "* Predict if a transaction is **fraudulent or not**.\n",
        "* Predict if a customer will **churn (leave) or stay**.\n",
        "\n",
        "---\n",
        "\n",
        "## **2. Multinomial Logistic Regression (Softmax Regression)**\n",
        "\n",
        "### **Definition**\n",
        "\n",
        "* Used when the **dependent variable has more than two categories** with **no natural ordering**.\n",
        "* Generalizes binary logistic regression by using the **softmax function**.\n",
        "\n",
        "### **Equation**\n",
        "\n",
        "For class $k$ (out of $K$ classes):\n",
        "\n",
        "$$\n",
        "P(Y=k|X) = \\frac{e^{\\beta_{0k} + \\beta_{1k}X_1 + \\dots + \\beta_{nk}X_n}}{\\sum_{j=1}^{K} e^{\\beta_{0j} + \\beta_{1j}X_1 + \\dots + \\beta_{nj}X_n}}\n",
        "$$\n",
        "\n",
        "* Ensures all probabilities add up to 1.\n",
        "* Prediction = class with highest probability.\n",
        "\n",
        "### **Example Applications**\n",
        "\n",
        "* Predict type of **fruit** (apple, orange, banana).\n",
        "* Predict **mode of transport** (car, bus, train, bicycle).\n",
        "* Classifying **news articles** into topics (sports, politics, business).\n",
        "\n",
        "---\n",
        "\n",
        "## **3. Ordinal Logistic Regression**\n",
        "\n",
        "### **Definition**\n",
        "\n",
        "* Used when the **dependent variable has more than two categories with a natural order**.\n",
        "* Example: Rating (Low, Medium, High), Education level (High School < Bachelor < Master < PhD).\n",
        "\n",
        "### **Equation**\n",
        "\n",
        "* Uses **cumulative logits** instead of simple logits:\n",
        "\n",
        "$$\n",
        "\\log \\left( \\frac{P(Y \\leq j)}{P(Y > j)} \\right) = \\theta_j - (\\beta_1X_1 + \\dots + \\beta_nX_n)\n",
        "$$\n",
        "\n",
        "Where:\n",
        "\n",
        "* $j$ = threshold for categories (e.g., cut-off between Low and Medium).\n",
        "* $\\theta_j$ = threshold parameter for category $j$.\n",
        "\n",
        "### **Example Applications**\n",
        "\n",
        "* Predicting **customer satisfaction** (Very Unsatisfied → Very Satisfied).\n",
        "* Predicting **disease severity** (Mild, Moderate, Severe).\n",
        "* Predicting **credit ratings** (AAA, AA, A, BBB...).\n",
        "\n",
        "---\n",
        "\n",
        "## **4. Quick Comparison Table**\n",
        "\n",
        "| Variant                  | Outcome Variable         | Function Used    | Example                              |\n",
        "| ------------------------ | ------------------------ | ---------------- | ------------------------------------ |\n",
        "| **Binary Logistic**      | 2 categories (0/1)       | Sigmoid          | Spam vs Not Spam                     |\n",
        "| **Multinomial Logistic** | >2 categories, unordered | Softmax          | Classify animals (dog, cat, bird)    |\n",
        "| **Ordinal Logistic**     | >2 categories, ordered   | Cumulative Logit | Customer satisfaction (Low/Med/High) |\n",
        "\n",
        "---\n",
        "\n",
        "✅ **Key Takeaways:**\n",
        "\n",
        "* **Binary Logistic Regression** → 2 classes.\n",
        "* **Multinomial Logistic Regression** → multiple unordered classes (softmax).\n",
        "* **Ordinal Logistic Regression** → multiple ordered classes (cumulative logit).\n",
        "\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "iWFQDFfwK3-S"
      }
    }
  ]
}